
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multiple Random Variables &#8212; Modelling of Uncertainty</title>
    
  <link rel="stylesheet" href="_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Estimating Probabilities" href="estimateProbability.html" />
    <link rel="prev" title="Discrete and Continuous Random Variables" href="ProbabilityUnivariate.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/hdmlogomed.jpg" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Modelling of Uncertainty</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Basic Concepts of Probability Theory for AI and ML
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Probability Theory
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="ProbabilityUnivariate.html">
   Discrete and Continuous Random Variables
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Multiple Random Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estimateProbability.html">
   Estimating Probabilities
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Exercises and Applications
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="exampleProbEst.html">
   Estimation of Probabilities from Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="parametricClassification1D.html">
   Bayes- and Naive Bayes Classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Thrombosis.html">
   Correlation is not Causality
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Bayesian Networks
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="BayesNetAsia.html">
   Bayesian Networks with pyAgrum
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BayesNetLearningWithPandas.html">
   Learn CPTs of Bayesian Netork
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/ProbabilityMultivariate.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/ProbabilityMultivariate.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-to-be-used-in-this-section">
   Example to be used in this section
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-probability">
   Joint Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#independence-of-random-variables">
   Independence of random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#marginal-probability">
   Marginal Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conditional-probability">
   Conditional Probability
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#multiple-continuous-random-variables">
   Multiple Continuous Random Variables
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="multiple-random-variables">
<h1>Multiple Random Variables<a class="headerlink" href="#multiple-random-variables" title="Permalink to this headline">¶</a></h1>
<p>In the <a class="reference internal" href="ProbabilityUnivariate.html"><span class="doc std std-doc">previous section</span></a> discrete and continuous random variables, the concept of probability and common distributions of random variables have been introduced.</p>
<p>Recall, that a a random variable <span class="math notranslate nohighlight">\(X\)</span> is a variable that can take multiple values <span class="math notranslate nohighlight">\(X=x_i\)</span> and the set of possible values, that can be taken by the variable is denoted by <span class="math notranslate nohighlight">\(V(X)\)</span>.</p>
<p>Now we consider the case of multiple random variables. In the case that we have only 2 or 3 of them we usually denote them by <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>, respectively. In the general case of <span class="math notranslate nohighlight">\(N\)</span> random variables they are denoted by <span class="math notranslate nohighlight">\(
X_1,X_2,\ldots, X_N\)</span> and their corresponding values <span class="math notranslate nohighlight">\(x_1,x_2,\ldots, x_N\)</span>.</p>
<div class="section" id="example-to-be-used-in-this-section">
<h2>Example to be used in this section<a class="headerlink" href="#example-to-be-used-in-this-section" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">vacData</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;vaccinated20210409.xlsx&quot;</span><span class="p">,</span><span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">vacData</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BionTech</th>
      <th>AstraZeneca</th>
      <th>Moderna</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Vaccinated Once</th>
      <td>7509918</td>
      <td>690925</td>
      <td>3480507</td>
    </tr>
    <tr>
      <th>Vacinated Twice</th>
      <td>4674351</td>
      <td>225050</td>
      <td>2491</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sumAll</span><span class="o">=</span><span class="n">vacData</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of vaccinated people in Germany by 09.04.2021: &quot;</span><span class="p">,</span><span class="n">sumAll</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total number of vaccinated people in Germany by 09.04.2021:  16583242
</pre></div>
</div>
</div>
</div>
<p>In this example we have two random variables: <code class="docutils literal notranslate"><span class="pre">Vaccinated</span></code> and <code class="docutils literal notranslate"><span class="pre">Vaccine</span></code>. For <code class="docutils literal notranslate"><span class="pre">Vaccinated</span></code> the value range is</p>
<div class="math notranslate nohighlight">
\[V(\mbox{Vaccinated})=\left\{once,twice\right\}.\]</div>
<p>This means that we are just interested in the vaccinated people - all others are out of scope in our context.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">Vaccine</span></code> the value range is</p>
<div class="math notranslate nohighlight">
\[V(\mbox{Vaccine})=\left\{BionTech, AstraZeneca, Moderna\right\}.\]</div>
</div>
<div class="section" id="joint-probability">
<h2>Joint Probability<a class="headerlink" href="#joint-probability" title="Permalink to this headline">¶</a></h2>
<p>The <strong>Joint Probability</strong> of two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> measures the probability that variable <span class="math notranslate nohighlight">\(X\)</span> takes the value <span class="math notranslate nohighlight">\(x_i\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\(Y\)</span> takes the value <span class="math notranslate nohighlight">\(y_j\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(X=x_i,Y=y_j) \quad \mbox{ or for short} \quad P(x_i,y_j).
\]</div>
<p>Note, that the comma between the two variables stands for <strong>and</strong>.</p>
<p>The set of all joint probabilites
$<span class="math notranslate nohighlight">\(
P(X=x_i,Y=y_j)  \quad \forall \quad x_i \in V(X), y_j \in V(Y)
\)</span>$</p>
<p>is called the <strong>Joint Probability Distribution</strong> of the two variables.</p>
<p>In the example the Joint Probability Distribution can be obtained by just dividing the absolute numbers, given in the entries of the dataframe <code class="docutils literal notranslate"><span class="pre">vacData</span></code> by the total amount of vaccinated people (16.583.242):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probDist</span><span class="o">=</span><span class="n">vacData</span><span class="o">/</span><span class="n">sumAll</span>
<span class="n">probDist</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>BionTech</th>
      <th>AstraZeneca</th>
      <th>Moderna</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Vaccinated Once</th>
      <td>0.452862</td>
      <td>0.041664</td>
      <td>0.209881</td>
    </tr>
    <tr>
      <th>Vacinated Twice</th>
      <td>0.281872</td>
      <td>0.013571</td>
      <td>0.000150</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Given this table, we know for example, that the probability that among the population of vaccinated people the probability that a person has been vaccinated once <em>and</em> the vaccine is <em>Moderna</em> is</p>
<div class="math notranslate nohighlight">
\[
P(Vaccinated=once,Vaccine=Moderna)=0.21.
\]</div>
<p>Correspondingly the Joint Probability of <span class="math notranslate nohighlight">\(N\)</span> random variables</p>
<div class="math notranslate nohighlight">
\[
P(X_1=x_{i_1},X_2=x_{i_2}, \ldots, X_N=x_{i_N}) \quad \mbox{ or for short} \quad P(x_{i_1},x_{i_2}, \ldots, x_{i_N})
\]</div>
<p>measures the probability, that <span class="math notranslate nohighlight">\(X_1\)</span> takes the value <span class="math notranslate nohighlight">\(x_{i_1}\)</span> <strong>and</strong> <span class="math notranslate nohighlight">\(X_2\)</span> takes the value <span class="math notranslate nohighlight">\(x_{i_2}\)</span> <strong>and</strong>, … <span class="math notranslate nohighlight">\(X_N\)</span> takes the value <span class="math notranslate nohighlight">\(x_{i_N}\)</span>. The set of all Joint Probabilities for all possible values in the value range of the variables is called the Joint Probability of the given <span class="math notranslate nohighlight">\(N\)</span> random variables.</p>
<p>In the case of continuous variables, the joint probability distribution can be expressed either in terms of a joint cumulative distribution function (<strong>cdf</strong>) or in terms of a joint probability density function (<strong>pdf</strong>). For discrete random variables the probability mass function (<strong>pmf</strong>). These in turn can be used to find two other types of distributions: the <a class="reference external" href="#margProb">marginal distribution</a> giving the probabilities for any one of the variables with no reference to any specific ranges of values for the other variables, and the <a class="reference external" href="#condprob">conditional probability distribution</a>. Both of them are described below.</p>
<p><a id="independence"></a></p>
</div>
<div class="section" id="independence-of-random-variables">
<h2>Independence of random variables<a class="headerlink" href="#independence-of-random-variables" title="Permalink to this headline">¶</a></h2>
<p>Random variables can be dependent or independent. A pair of random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is called independent, if the value of the value of the other has no influence on the value of the other. For example, if you roll a dice twice in a row, the result of the second roll will be completely independent of the result of the first roll.</p>
<p>If and only if the random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent of each other, the conditional probabilty can be calculated by factorisation:</p>
<div class="math notranslate nohighlight">
\[
P(X=x_{i},Y=y_j)= P(X=x_{i}) \cdot P(Y=y_j)
\]</div>
<p>For example, in the case of a regular dice, the probability, that in the first roll a <em>1</em> and in the second roll a <em>2</em> will be obtained is</p>
<div class="math notranslate nohighlight">
\[
P(X=1,Y=2)= P(X=1) \cdot P(Y=2)=\frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}
\]</div>
<p>On the other hand experiments such as <strong>Lotto</strong>, where balls are drawn without laying them back are dependent: The result of the second draw certainly depends on the result of the first draw.</p>
<p><a id="margProb"></a></p>
</div>
<div class="section" id="marginal-probability">
<h2>Marginal Probability<a class="headerlink" href="#marginal-probability" title="Permalink to this headline">¶</a></h2>
<p>The marginal distribution of a subset of a collection of random variables is the probability distribution of the variables contained in the subset. It gives the probabilities of various values of the variables in the subset without reference to the values of the other variables.</p>
<p>Assume the case that for a set of random variables <span class="math notranslate nohighlight">\(X_1,X_2,\ldots, X_N\)</span> the Joint Probability Distribution, i.e. all probabilities of type</p>
<div class="math notranslate nohighlight">
\[
P(X_1=x_{i_1},X_2=x_{i_2}, \ldots, X_N=x_{i_N}) 
\]</div>
<p>are known, but we interested in the Joint Probability Distribution of a subset</p>
<div class="math notranslate nohighlight">
\[
\left\{ X_{i_1},X_{i_2},\ldots, X_{i_Z} \right\} \subset \left\{ X_1,X_2,\ldots, X_N \right\},
\]</div>
<p>i.e. probabilities of type</p>
<div class="math notranslate nohighlight">
\[
P(X_{i_1},X_{i_2},\ldots, X_{i_Z}). 
\]</div>
<p>How can we determine this Joint Probabilities of the subset?</p>
<p>The answer is: By marginalizing all random variables, which are not in the subset.</p>
<p>In the most simple case we have two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> and we know all Joint Probabilities of type <span class="math notranslate nohighlight">\(P(X=x_i,Y=y_j)\)</span>. If we are interested in <span class="math notranslate nohighlight">\(P(X=x_i)\)</span>, we can obtain this value by marginalising variable <span class="math notranslate nohighlight">\(Y\)</span>, which means that we calculate the sum of the Joint Probabilities <span class="math notranslate nohighlight">\(P(X=x_i,Y=y_j)\)</span> over all possible values <span class="math notranslate nohighlight">\(y_j \in V(Y)\)</span>.</p>
<p><strong>Marginalisation law:</strong></p>
<div class="amsmath math notranslate nohighlight" id="equation-afc1e988-ab03-4462-9a77-acdad9c50dbe">
<span class="eqno">(1)<a class="headerlink" href="#equation-afc1e988-ab03-4462-9a77-acdad9c50dbe" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(x_i)=\sum\limits_{y_j \in V(Y)} P(x_i,y_j)
\label{eq:marg} \tag{1}
\end{equation}\]</div>
<p>The <strong>marginal variables</strong> are those variables in the subset of variables being retained (<span class="math notranslate nohighlight">\(X\)</span> in the equation above).</p>
<p>Similarly, in the case of 3 random variables <span class="math notranslate nohighlight">\(X,Y\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> one can obtain the probabilities of the marginal variable <span class="math notranslate nohighlight">\(X\)</span> from the Joint Probability Distribution of the 3 variables by marginalising <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(Z\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(x_i)=\sum\limits_{y_j \in V(Y)} \sum\limits_{z_k \in V(Z)} P(x_i,y_j,z_k)
\]</div>
<p>This rule can easily be generalized to an arbitrary set of random variables and arbitrary subsets thereof.</p>
<p>In the <em>Vaccination Example</em> we can easily obtain the marginal probability <span class="math notranslate nohighlight">\(P(Vaccinated)\)</span> for the variable <code class="docutils literal notranslate"><span class="pre">Vaccinated</span></code> by calculating the row-wise sum of the Joint Probability Table. Similarly, the marginal probability <span class="math notranslate nohighlight">\(P(Vaccine)\)</span> for the variable <code class="docutils literal notranslate"><span class="pre">Vaccine</span></code> is the column-wise sum in the Joint Probability Table.</p>
<p>Below the table of Joint Probabilities has been extended by an</p>
<ul class="simple">
<li><p>additional column, which contains the marginal probabilities <span class="math notranslate nohighlight">\(P(Vaccinated)\)</span></p></li>
<li><p>additional row, which contains the marginal probabilities <span class="math notranslate nohighlight">\(P(Vaccine)\)</span></p></li>
</ul>
<p>For example the marginal probability</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(Vaccine=BionTech)=0.73\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(Vaccinated=Twice)=0.30\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">margProb</span><span class="o">=</span><span class="n">probDist</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">margProb</span><span class="p">[</span><span class="s2">&quot; &quot;</span><span class="p">]</span><span class="o">=</span><span class="n">probDist</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">margProb</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot; &quot;</span><span class="p">,:]</span><span class="o">=</span><span class="n">margProb</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">margProb</span>
<span class="c1">#marginCols</span>

<span class="k">def</span> <span class="nf">highlight_margins</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="s1">&#39;background-color: red&#39;</span>
    <span class="n">g</span> <span class="o">=</span> <span class="s1">&#39;background-color: green&#39;</span>
    <span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">r</span>
    <span class="n">df1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">g</span>
    <span class="k">return</span> <span class="n">df1</span>  


<span class="n">margProb</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">highlight_margins</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style  type="text/css" >
#T_0430c_row0_col3,#T_0430c_row1_col3{
            background-color:  red;
        }#T_0430c_row2_col0,#T_0430c_row2_col1,#T_0430c_row2_col2{
            background-color:  green;
        }</style><table id="T_0430c_" ><thead>    <tr>        <th class="blank level0" ></th>        <th class="col_heading level0 col0" >BionTech</th>        <th class="col_heading level0 col1" >AstraZeneca</th>        <th class="col_heading level0 col2" >Moderna</th>        <th class="col_heading level0 col3" > </th>    </tr></thead><tbody>
                <tr>
                        <th id="T_0430c_level0_row0" class="row_heading level0 row0" >Vaccinated Once</th>
                        <td id="T_0430c_row0_col0" class="data row0 col0" >0.452862</td>
                        <td id="T_0430c_row0_col1" class="data row0 col1" >0.041664</td>
                        <td id="T_0430c_row0_col2" class="data row0 col2" >0.209881</td>
                        <td id="T_0430c_row0_col3" class="data row0 col3" >0.704407</td>
            </tr>
            <tr>
                        <th id="T_0430c_level0_row1" class="row_heading level0 row1" >Vacinated Twice</th>
                        <td id="T_0430c_row1_col0" class="data row1 col0" >0.281872</td>
                        <td id="T_0430c_row1_col1" class="data row1 col1" >0.013571</td>
                        <td id="T_0430c_row1_col2" class="data row1 col2" >0.000150</td>
                        <td id="T_0430c_row1_col3" class="data row1 col3" >0.295593</td>
            </tr>
            <tr>
                        <th id="T_0430c_level0_row2" class="row_heading level0 row2" > </th>
                        <td id="T_0430c_row2_col0" class="data row2 col0" >0.734734</td>
                        <td id="T_0430c_row2_col1" class="data row2 col1" >0.055235</td>
                        <td id="T_0430c_row2_col2" class="data row2 col2" >0.210031</td>
                        <td id="T_0430c_row2_col3" class="data row2 col3" >1.000000</td>
            </tr>
    </tbody></table></div></div>
</div>
<p>As can be seen here, the marginal probabilities are typically displayed  in the margins of the Joint Distribution Table.</p>
<p><strong>Independence Test:</strong> As described in <a class="reference external" href="#independence">subsection Independence</a>, <span class="math notranslate nohighlight">\(P(X,Y)=P(X) \cdot P(Y)\)</span>, if and only if the two random variables are independent of each other. From the joint probability values and the marginal probabilities in the example above, we see that</p>
<div class="math notranslate nohighlight">
\[
P(BionTech,Twice)=0.28
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
P(BionTech) \cdot P(Twice) = 0.73 \cdot 0.3 = 0.219
\]</div>
<p>are significantly different. Therefore the two variables are not independent of each other.</p>
<p><a id="condprob"></a></p>
</div>
<div class="section" id="conditional-probability">
<h2>Conditional Probability<a class="headerlink" href="#conditional-probability" title="Permalink to this headline">¶</a></h2>
<p>Given two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> the conditional probability</p>
<div class="math notranslate nohighlight">
\[
P(X=x_i | Y=y_j) \quad \mbox{ or for short } \quad P(x_i | y_j)
\]</div>
<p>is the probability that <span class="math notranslate nohighlight">\(X\)</span> takes the value <span class="math notranslate nohighlight">\(x_i\)</span>, if it is known, that <span class="math notranslate nohighlight">\(Y\)</span> has the value <span class="math notranslate nohighlight">\(y_j\)</span>. Instead of <em>if it is known</em> one can also say <em>if it has been observed</em>.</p>
<p>The <strong>marginal probability</strong>, as introduced above, is the probability of a single event occurring, independent of other events. A <strong>conditional probability</strong>, on the other hand, is the probability that an event occurs given that another specific event has already occurred. This means that the calculation for one variable is dependent on the value of another variable.</p>
<p>The conditional distribution of a variable given another variable is the joint distribution of both variables divided by the marginal distribution of the other variable:</p>
<div class="amsmath math notranslate nohighlight" id="equation-66384400-0dcf-475e-9449-584173561ced">
<span class="eqno">(2)<a class="headerlink" href="#equation-66384400-0dcf-475e-9449-584173561ced" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(x_i | y_j)=\frac{P(x_i,y_j)}{P(y_j)}
\label{eq:cond} \tag{2}
\end{equation}\]</div>
<p>In the general case of <span class="math notranslate nohighlight">\(N\)</span> random variables <span class="math notranslate nohighlight">\(X_1,X_2,\ldots, X_N\)</span>, the values of an arbitrary subset of variables can be known and one can ask for the joint probability of all other variables. For example if the values of <span class="math notranslate nohighlight">\(X_k, X_{k+1}, \ldots X_N\)</span> are known, the probability for <span class="math notranslate nohighlight">\(X_1, X_{2}, \ldots X_{k-1}\)</span> given these known values is</p>
<div class="math notranslate nohighlight">
\[
= P(x_{i_1}, x_{i_2}, \ldots x_{i_{k-1}} | x_{i_k}, x_{i_{k+1}}, \ldots x_{i_{N}}  )
=\frac{P(x_{i_1}, x_{i_2},  \ldots x_{i_{N}}  )}{P(x_{i_k}, x_{i_{k+1}}, \ldots x_{i_{N}}  )}
\]</div>
<p>In general for two disjoint subsets of random variables <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(V\)</span>, the conditional probability <span class="math notranslate nohighlight">\(P(U|V)\)</span> for <span class="math notranslate nohighlight">\(U\)</span>, if the variables in <span class="math notranslate nohighlight">\(V\)</span> are known, is the joint probability <span class="math notranslate nohighlight">\(P(U \cup V)\)</span> divided by the marginal probability of the ovservation <span class="math notranslate nohighlight">\(P(V)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P(U|V) =\frac{P(U \cup V)}{P(V)}
\]</div>
<p><strong>Example:</strong> For the given data on vaccinated people in Germany, we like to know the probability, that a completely vaccinated people has got BionTech. I.e. we have to calculate <span class="math notranslate nohighlight">\(P(BionTech|Twice)\)</span>. This can be calculated as follows:</p>
<div class="math notranslate nohighlight">
\[
P(BionTech|Twice) = \frac{P(BionTech, Twice)}{P(Twice)} = \frac{0.28}{0.3} =0.933
\]</div>
<p><strong>Chain Rule:</strong>
By rearranging equation <span class="math notranslate nohighlight">\(\eqref{eq:cond}\)</span> we can calculate a joint probability as a product of a conditional probability and an a-priori probability:</p>
<div class="math notranslate nohighlight">
\[
p(x_i,y_j)= p(x_i|y_j)\cdot p(y_j)
\]</div>
<p>This is actually the most simple case of the chain rule.</p>
<p>For 3 variables we can write:</p>
<div class="math notranslate nohighlight">
\[
p(x_i,y_j,z_k)= p(x_i|y_j,z_j)\cdot p(y_j,z_j).
\]</div>
<p>Since the last factor on the right hand side of this equation can be again written as</p>
<div class="math notranslate nohighlight">
\[
p(y_j,z_j)= p(y_j|z_k)\cdot p(z_k), 
\]</div>
<p>we finally obtain:</p>
<div class="math notranslate nohighlight">
\[
p(x_i,y_j,z_k)= p(x_i|y_j,z_j)\cdot p(y_j|z_k)\cdot p(z_k)
\]</div>
<p>I.e. the joint probability can be expressed as a product of conditional probabilities and an a-priori probability.</p>
<p>This can be generalized to the case of <span class="math notranslate nohighlight">\(N\)</span> random variables. The general form of the chain rule is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
P(x_{i_1}, x_{i_2},  \ldots x_{i_{N}}) = P(x_{i_1} | x_{i_2},  \ldots x_{i_{N}}  ) \cdot P(x_{i_2} | x_{i_3},  \ldots x_{i_{N}}) \cdot P(x_{i_3} | x_{i_4},  \ldots x_{i_{N}})  \cdots P(x_{i_{N}}) \\
= \prod\limits_{j=1}^N P(x_{i_j} | x_{i_{j+1}},  \ldots x_{i_{N}}  )
\end{split}\]</div>
<p><strong>Bayes Rule and Bayesian Inference:</strong></p>
<p>From equation <span class="math notranslate nohighlight">\(\eqref{eq:cond}\)</span> one of the central theorems of Artificial Intelligence and Machine Learning can be deduced: The <strong>Bayes Theorem:</strong></p>
<div class="amsmath math notranslate nohighlight" id="equation-418fb8f7-1464-4fa0-9d57-686bfb0c5ade">
<span class="eqno">(3)<a class="headerlink" href="#equation-418fb8f7-1464-4fa0-9d57-686bfb0c5ade" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(x_i | y_j)=\frac{P(y_j | x_i) P(x_i)}{P(y_j)}
\label{eq:bayes} \tag{3}
\end{equation}\]</div>
<p>In this equation</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x_i | y_j)\)</span> is the <em>a-posteriori probability</em></p></li>
<li><p><span class="math notranslate nohighlight">\(P(x_i)\)</span> is the <em>a-priori probability</em></p></li>
<li><p><span class="math notranslate nohighlight">\(P(y_j | x_i)\)</span> is the <em>likelihood</em></p></li>
<li><p><span class="math notranslate nohighlight">\(P(y_j)\)</span> is the <em>evidence</em>.</p></li>
</ul>
<p>By applying marginalisation (<span class="math notranslate nohighlight">\(\eqref{eq:marg}\)</span>) and equation <span class="math notranslate nohighlight">\(\eqref{eq:cond}\)</span> to the evidence (denominator) in the Bayes Theorem, we get:</p>
<div class="amsmath math notranslate nohighlight" id="equation-67b0cb21-cb71-4ea4-afec-407e6847f109">
<span class="eqno">(4)<a class="headerlink" href="#equation-67b0cb21-cb71-4ea4-afec-407e6847f109" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(x_i | y_j)=\frac{P(y_j | x_i) P(x_i)}{\sum\limits_{x_k \in V(X)}P(y_j | x_k) P(x_k)}
\label{eq:bayes2} \tag{4}
\end{equation}\]</div>
<p>For <strong>Bayesian Inference</strong> this equation is applied as follows: Assume that you want to estimate the output of a random variable <span class="math notranslate nohighlight">\(X\)</span>, in particular the probability that the random variable takes the value <span class="math notranslate nohighlight">\(X=x_i\)</span>.</p>
<p>If <strong>prior knowledge</strong> on the distribution of <span class="math notranslate nohighlight">\(X\)</span> is available than <span class="math notranslate nohighlight">\(P(x_i)\)</span> is known. Now, assume that you know the value <span class="math notranslate nohighlight">\(y_i\)</span> of another random variable <span class="math notranslate nohighlight">\(Y\)</span>, which is not independent of <span class="math notranslate nohighlight">\(X\)</span>. Moreover, you have a model <span class="math notranslate nohighlight">\(p(y_i|x_i)\)</span>, which describes the probability of <span class="math notranslate nohighlight">\(Y=y_j\)</span>, if <span class="math notranslate nohighlight">\(X=x_i\)</span> is fixed. Since <span class="math notranslate nohighlight">\(Y\)</span> is not independent of <span class="math notranslate nohighlight">\(X\)</span>, the observation of <span class="math notranslate nohighlight">\(Y=y_j\)</span> provides a better estimate for the probability of <span class="math notranslate nohighlight">\(X=x_i\)</span>. This better estimate is the <strong>a-posteriori</strong> <span class="math notranslate nohighlight">\(P(x_i | y_j)\)</span>, which is calculated according to equation <span class="math notranslate nohighlight">\(\eqref{eq:cond}\)</span>.</p>
<p>Certainly, the Bayes Theorem is not restricted to only two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. It can be generalized to arbitrary disjoint sets of random variables <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(V\)</span> as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b6e43b3b-2e1e-4099-92a4-33a4093a12e2">
<span class="eqno">(5)<a class="headerlink" href="#equation-b6e43b3b-2e1e-4099-92a4-33a4093a12e2" title="Permalink to this equation">¶</a></span>\[\begin{equation}
P(U | V)=\frac{P(V | U) P(U)}{P(V)}.
\label{eq:bayesU} \tag{5}
\end{equation}\]</div>
<p>Visually, the Bayes Theorem can be explained as shown below:</p>
<figure align="center">
<img src="https://maucher.home.hdm-stuttgart.de/Pics/probVisual.png" style="width:600px" align="center">
<figcaption>
    Visualisation of Bayes Theorem, Joint- and Conditional Probabilities.
</figcaption></div>
<div class="section" id="multiple-continuous-random-variables">
<h2>Multiple Continuous Random Variables<a class="headerlink" href="#multiple-continuous-random-variables" title="Permalink to this headline">¶</a></h2>
<p>Independence, Marginalisation, Conditional Probability and the Bayes Theorem, which has been introduced for discrete random variables above, also hold for continuous variables. However, in the <strong>marginalisation rule</strong> (equation <span class="math notranslate nohighlight">\(\eqref{eq:marg}\)</span>) the sum over discrete joint probabilities must be replaced by the integral of the <strong>joint probability function</strong> <span class="math notranslate nohighlight">\(p_{X,Y}(x,y)\)</span> in order to calculate the <strong>marginal probability density function</strong> <span class="math notranslate nohighlight">\(p_X(x)\)</span> as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8dcecbf7-5d9e-4e63-8307-e251a377a11b">
<span class="eqno">(6)<a class="headerlink" href="#equation-8dcecbf7-5d9e-4e63-8307-e251a377a11b" title="Permalink to this equation">¶</a></span>\[\begin{equation}
p_X(x)=\int_{a}^{b} p_{X,Y}(x,y) dy,
\end{equation}\]</div>
<p>with <span class="math notranslate nohighlight">\(y \in \left[a,b\right]\)</span>.</p>
<p>The most popular multi-dimensional joint probability function for continuous variables is the <strong>multi-dimensional Gaussian distribution</strong>, which is defined as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4b4b97c8-e8e6-4a6e-ab76-3b6d347fe26d">
<span class="eqno">(7)<a class="headerlink" href="#equation-4b4b97c8-e8e6-4a6e-ab76-3b6d347fe26d" title="Permalink to this equation">¶</a></span>\[\begin{equation}
  p(\mathbf{x})=\frac{1}{(2 \pi)^{d/2} |\Sigma|^{1/2}} \exp\left[-\frac{1}{2}(\mathbf{x}- \boldsymbol\mu)^T \Sigma^{-1}(\mathbf{x}-\boldsymbol\mu)\right] , \quad -\infty &lt; x &lt; \infty 
\label{eq:pdfmulti}
\end{equation}\]</div>
<p>Here</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{x}=\left[x_1,x_2,\ldots,x_d \right]\)</span> are the values of <span class="math notranslate nohighlight">\(d\)</span> random variables, which are jointly Gaussian distributed.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{\mu}=[\mu_1,\mu_2,\ldots, \mu_d]\)</span> is <strong>mean-value-vektor</strong></p></li>
<li><p>the <strong>covariance matrix</strong> is
$<span class="math notranslate nohighlight">\( 
\Sigma = \left(
  \begin{array}{cccc}
  \sigma_{11}^2 &amp; \sigma_{12} &amp;\cdots &amp; \sigma_{1d} \\
  \sigma_{21} &amp; \sigma_{22}^2 &amp;\cdots &amp; \sigma_{2d} \\
  \vdots      &amp; \vdots      &amp; \ddots &amp;  \vdots \\
  \sigma_{d1} &amp; \sigma_{d2} &amp; \cdots &amp; \sigma_{dd}^2 \\
  \end{array} \right)
\)</span>$</p></li>
<li><p><span class="math notranslate nohighlight">\(|\Sigma|\)</span> is the determinant of the covariance matrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\Sigma^{-1}\)</span> is the inverse of the covariance matrix</p></li>
</ul>
<p>Below, the 2-dimensional Gaussian distribution with</p>
<div class="math notranslate nohighlight">
\[
\mathbf{\mu}=[0,0]
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\Sigma = \left(
	\begin{array}{cc}
	1.5 &amp; 0  \\
	0 &amp; 1.5  \\
	\end{array} \right)
\end{split}\]</div>
<p>is plotted.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gauss2d</span><span class="p">(</span><span class="n">mu</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">sigma</span><span class="o">=</span><span class="p">[</span><span class="mf">1.5</span><span class="p">,</span><span class="mf">1.5</span><span class="p">]):</span>
    
    <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span>

    <span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">w</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">mu</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">h</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">x_</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">y_</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_</span><span class="p">,</span> <span class="n">y_</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>

    <span class="n">normal_rv</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">normal_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xy</span><span class="p">)</span>
    <span class="n">z</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s1">&#39;F&#39;</span><span class="p">)</span>
    
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="n">rstride</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cstride</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">antialiased</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">z</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">cm</span>
<span class="n">_</span> <span class="o">=</span><span class="n">gauss2d</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ProbabilityMultivariate_27_0.png" src="_images/ProbabilityMultivariate_27_0.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ProbabilityUnivariate.html" title="previous page">Discrete and Continuous Random Variables</a>
    <a class='right-next' id="next-link" href="estimateProbability.html" title="next page">Estimating Probabilities</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Prof. Dr. Johannes Maucher<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>